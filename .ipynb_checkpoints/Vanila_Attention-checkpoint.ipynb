{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c54e5-2cf8-40ef-b77c-407d659e4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "# Load the configuration from the JSON file\n",
    "with open(r'C:\\Users\\Rishabh\\Documents\\3d-hcct\\config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53e26a-2611-49c2-95a0-5e2b0e84e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ViTForClassfication\n",
    "\n",
    "# Initialize the model with the loaded configuration\n",
    "model = ViTForClassfication(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547e1e1-8c79-4f5b-8a8c-1dceedd79751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "checkpoint_path = r'C:\\Users\\Rishabh\\training_output_metricsHCCT_best_model.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "# Remove 'module.' prefix if it exists\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k.replace('module.', '')  # strip the prefix\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict, strict=True)  # strict ensures all match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33ff70-41a4-4f0d-b135-2c76ae2eaded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "DataFolder = r'C:\\Users\\Rishabh\\Documents\\TrimeseData'\n",
    "CSVPath = r'C:\\Users\\Rishabh\\Documents\\TransBTS\\IXI.xlsx'\n",
    "Files = os.listdir(DataFolder)\n",
    "ixi_ids = [int(f[3:6]) for f in Files]\n",
    "print(ixi_ids)  # [2, 19, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23407b87-acc2-4006-bc40-8f35794b4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(CSVPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115567c-4092-4443-9724-75625224adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def white0(image, threshold=0):\n",
    "    \"\"\"\n",
    "    Standardize voxels with value > threshold\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        threshold: Threshold value\n",
    "\n",
    "    Returns:\n",
    "        Standardized image\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    mask = (image > threshold).astype(int)\n",
    "\n",
    "    # Vectorized implementation to avoid unnecessary memory allocation\n",
    "    image_h = image * mask\n",
    "\n",
    "    # Calculate mean and std only for relevant voxels\n",
    "    non_zero_voxels = np.sum(mask)\n",
    "    if non_zero_voxels > 0:\n",
    "        mean = np.sum(image_h) / non_zero_voxels\n",
    "\n",
    "        # More memory efficient way to calculate std\n",
    "        std_sum = np.sum((image_h - mean * mask) ** 2)\n",
    "        std = np.sqrt(std_sum / non_zero_voxels)\n",
    "\n",
    "        if std > 0:\n",
    "            normalized = mask * (image - mean) / std\n",
    "            # Use in-place operations to reduce memory usage\n",
    "            image = normalized + image * (1 - mask)\n",
    "            return image\n",
    "\n",
    "    # Default case\n",
    "    return np.zeros_like(image, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f9b95-27f9-4bd0-a895-d9811859ec5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()  # deterministic dropout/BN\n",
    "\n",
    "indx = 30\n",
    "filename = Files[indx]\n",
    "\n",
    "file_path = os.path.join(DataFolder, filename)\n",
    "img = nib.load(file_path)\n",
    "x_np = img.get_fdata(caching='unchanged').astype(np.float32)       # avoid float64 bloat\n",
    "\n",
    "inputvolume = white0(x_np)\n",
    "inputvolume = torch.from_numpy(inputvolume).unsqueeze(0).unsqueeze(0).to(device).float()\n",
    "inputvolume = inputvolume.to(device).type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out,all_attention = model(inputvolume, output_attentions=True)\n",
    "logits = out[0] if isinstance(out, (tuple, list)) else out\n",
    "_id = int(filename[3:6])\n",
    "AGE = df[df['IXI_ID']==_id]['AGE'].values[0]\n",
    "Predicted_Age = logits.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea255a5-4417-4aee-854c-c567bcd41541",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_Age, AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4e79a-3367-47dc-affe-2df25b0054f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_attention), all_attention[0].shape\n",
    "Attn = torch.stack(all_attention)\n",
    "Attn = torch.mean(Attn, dim=0)\n",
    "Attn = torch.mean(Attn, dim=0)\n",
    "Attn = torch.mean(Attn, dim=0)\n",
    "Attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3cc7f-c8db-4f3c-8959-f74dc2c13d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "att_mat = Attn\n",
    "residual_att = torch.eye(att_mat.size(1)).to(device=\"cpu\")\n",
    "aug_att_mat = att_mat + residual_att\n",
    "aug_att_mat = aug_att_mat / aug_att_mat.sum(dim=-1).unsqueeze(-1)\n",
    "\n",
    "# Recursively multiply the weight matrices\n",
    "joint_attentions = torch.zeros(aug_att_mat.size()).to(device=\"cpu\")\n",
    "joint_attentions[0] = aug_att_mat[0]\n",
    "\n",
    "for n in range(1, aug_att_mat.size(0)):\n",
    "    joint_attentions[n] = torch.matmul(aug_att_mat[n], joint_attentions[n - 1])\n",
    "\n",
    "# Attention from the output token to the input space.\n",
    "v = joint_attentions[0,1:].to(device=\"cpu\")\n",
    "print(len(v))\n",
    "mask = v.reshape(8, 8, 8).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d423158-4e08-4590-973b-eae359511987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Suppose mask.shape = (depth, height, width)\n",
    "zoom_factors = (91 / mask.shape[0],\n",
    "                109 / mask.shape[1],\n",
    "                91 / mask.shape[2])\n",
    "\n",
    "mask = zoom(mask, zoom_factors, order=1)  # order=1 â†’ bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c401f-8bf9-4be5-a98f-a2466fdb435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bd403-1bb8-4722-8ea7-75ed607c551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(mask[34], cmap='hot')  # mask is your 2D NumPy array\n",
    "plt.colorbar(label='Attention intensity')\n",
    "plt.title('Attention Map')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3f756-f850-480f-92ce-9ba46f5607ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example: pick a middle slice along z-axis\n",
    "slice_idx = x_np.shape[2] // 2  \n",
    "\n",
    "img_slice = x_np[:, :, slice_idx]\n",
    "mask_slice = mask[:, :, slice_idx]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Show base image\n",
    "plt.imshow(img_slice, cmap='gray')\n",
    "\n",
    "# Overlay mask with transparency\n",
    "plt.imshow(mask_slice, cmap='jet', alpha=0.5)  # alpha controls overlay strength\n",
    "plt.colorbar(label=\"Mask intensity\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187d5a3-d0b6-4948-8e9f-50d825427a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example: pick a middle slice along z-axis\n",
    "slice_idx = x_np.shape[0] // 2  \n",
    "\n",
    "img_slice = x_np[slice_idx, :, :]\n",
    "mask_slice = mask[slice_idx, :, :]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Show base image\n",
    "plt.imshow(img_slice, cmap='gray')\n",
    "\n",
    "# Overlay mask with transparency\n",
    "plt.imshow(mask_slice, cmap='jet', alpha=0.5)  # alpha controls overlay strength\n",
    "plt.colorbar(label=\"Mask intensity\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7f65b-3dc6-453f-a67e-286bd45b65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example: pick a middle slice along z-axis\n",
    "slice_idx = x_np.shape[1] // 2  \n",
    "\n",
    "img_slice = x_np[:, slice_idx, :]\n",
    "mask_slice = mask[:,slice_idx, :]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Show base image\n",
    "plt.imshow(img_slice, cmap='gray')\n",
    "\n",
    "# Overlay mask with transparency\n",
    "plt.imshow(mask_slice, cmap='jet', alpha=0.5)  # alpha controls overlay strength\n",
    "plt.colorbar(label=\"Mask intensity\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90e8d2-f7be-4cd7-adf6-fe1020169b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
